# -*- coding: utf-8 -*-
"""Lab5LaurentoGavin.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11uZe1ezSDYNpHF6rZ3OglUJTiPNyBh-E

# Penn State DS 200 
# Lab 5 Tweets Gathering 

## Instructor:Kory Blose
## TA: Md Touhidul Islam 


# Learning Objectives:
- Be able to apply and obtain approval for a Twitter Developer Account.
- Be able to obtain API keys and Access Tokens, which are needed for gathering tweets from Twitter.
- Be able to identify a set of keywords and hashtags for sampling tweets relevant to a topic of interest.
- Be able to install Tweepy, a Python library/module for tathering tweets using Twitter API.
- Be able to use API keys and Access Tokens to run a Tweets gathering Python code.
- Be able to read Tweets gathered as a Table.

# Exercises: 4
- Exercise 1: 20 points
- Exercise 2: 10 points
- Exercise 3: 10 points
- Exercise 4: 5 points
- Exercise 5: 10 points

# Total Points: 55 points

# Due Date: 5 pm, February 14

### Install Tweepy
The first thing we will do is to install a tweepy, a Python library/module for gathering tweets using Twitter API.
"""

!pip install tweepy

import tweepy
from tweepy import OAuthHandler
from tweepy import Stream
from tweepy.streaming import StreamListener

import sys
import os
import json
import time
import datetime
import re

import pandas as pd

"""# Mounting Google Drive

Like the previous labs, we need to mount Google Drive so that the collected tweets can be saved there.
"""

from google.colab import drive
drive.mount('/content/drive')

"""### Python Code for Gathering Tweets
The following code defines a group of code that, together, "listens" (responds) to tweets (sent from Twitter API) that match the keywords and hashtags specified.  The code also filters out non-English tweets, and performs some simple preprocessing (e.g., remove non-ASCII characters in the body of the tweet), so that we do not need to worry about them later.
"""

class MyListener(StreamListener):
    def __init__(self, raw_file, csv_file, text_file, max_num=300):
        super().__init__()
        self.raw_file = raw_file
        self.csv_file = csv_file
        self.text_file = text_file
        self.max_num = max_num
        self.count = 0
        self.start_time = time.time()

    def on_data(self, data):
        # Filter out special cases
        if data.startswith('{"limit":'):
            return

        # Filter out non-English tweets
        tweet = json.loads(data)
        if tweet['lang'] != 'en':
            return
        # if 'retweeted_status' in tweet:
        #     return

        # Extract fields from tweet and write to csv_file
        user_id = tweet['user']['id']
        user_name = tweet['user']['name']
        tweet_time = tweet['created_at']
        location = tweet['user']['location']
        text = tweet['text'].strip().replace('\n', ' ').replace('\t', ' ')

        # Remove non-ASCII characters and commas in user_name and location
        if user_name is not None:
            user_name = ''.join([c if ord(c) < 128 else '' for c in user_name])
            user_name = user_name.replace(',', '')
        if location is not None:
            location = ''.join([c if ord(c) < 128 else '' for c in location])
            location = location.replace(',', '')

        # Remove non-ASCII characters in text
        text = ''.join([c if ord(c) < 128 else '' for c in text])
        # Replace commas with space
        text = text.replace(',', ' ')
        # Replace double quotes with blanks
        text = re.sub(r'\"', '', text)
        # Replace consecutive underscores with space
        text = re.sub(r'[_]{2,}', ' ', text)
        # Remove all consecutive whitespace characters
        text = ' '.join(text.split())

        # Check if csv_file, text_file exist
        # If not, create them and write the heads
        if not os.path.isfile(self.csv_file):
            with open(self.csv_file, 'w') as f:
                f.write(','.join(['user_id', 'user_name', 'tweet_time', 'location', 'text']) + '\n')
        if not os.path.isfile(self.text_file):
            with open(self.text_file, 'w') as f:
                f.write('text\n')

        with open(self.raw_file, 'a') as f_raw, open(self.csv_file, 'a') as f_csv, open(self.text_file, 'a') as f_text:
            # Write to files
            f_raw.write(data.strip() + '\n')
            f_csv.write(','.join(map(str, [user_id, user_name, tweet_time, location, text])) + '\n')
            f_text.write(text + '\n')

            # Increment count
            self.count += 1
            # if self.count % 10 == 0 and self.count > 0:
            sys.stdout.write('\r{}/{} tweets downloaded'.format(self.count, self.max_num))
            sys.stdout.flush()

            # Check if reaches the maximum tweets number limit
            if self.count == self.max_num:
                print('\nMaximum number reached.')
                end_time = time.time()
                elapse = end_time - self.start_time
                print('It took {} seconds to download {} tweets'.format(elapse, self.max_num))
                sys.exit(0)

    def on_error(self, status):
        print(status)
        return True

# Get the str representation of the current date and time    
def current_datetime_str():
    return format(datetime.datetime.now(), "%Y-%m-%d_%H-%M-%S")

"""# Establish a Twitter Developer Account

Follow the instructions in the slides for Lab5 to obtain the approval for your Twitter Developer Account.

## Exercise 1 (20 points)
Paste your API Key, API Secret Key, Access Token, and Access Token Secret into the four strings below, which were assigned to 4 corresponding variables: consumer_key, consumer_secret, access_token, and access_secret for obtaining authentication from Twitter API before 
real-time Tweets (that match your keywords and hashtags) can be gathered by the Python code. 

#### Note: Make sure you copy each key exactly as they are.  Especially, pay attention to the first character and the last character to make sure you did not miss any of them.  Also, double check you did not accidentently include space or left parenthesis when you copy keys and token.
#### Create a keywords.txt file and upload it from your computer to Google Drive under a Tweets folder in DS200Labs
"""

def main():
    # Path for Google Drive for reading keywords and writing Tweets Gathered
    data_directory ='/content/drive/My Drive/DS200Labs/Tweets/'
    # Paste your keys and token below.  
    


    auth = OAuthHandler(consumer_key, consumer_secret)
    auth.set_access_token(access_token, access_secret)
    api = tweepy.API(auth)

    # Welcome
    print('===========================================================')
    print('Welcome to the user interface of gathering tweets pipeline!')
    print('You can press "Ctrl+C" at anytime to abort the program.')
    print('===========================================================')
    print()

    # Prompt for input keywords
    methods = ['manual', 'file']
    print('How do you want to specify your key words?')
    while True:
        m = input('Type "manual" or "file" >>> ')
        if m in methods:
            break
        else:
            print('\"{}\" is an invalid input! Please try again.\n'.format(m))

    # Choose keywords:
    if m == 'file':
        print('===========================================================')
        print('Please input the file name that contains your key words.')
        print('Notes:')
        print('    The file should contain key words in one or multiple lines, and multiple key words should be separated by *COMMA*.')
        print('        For example: NBA, basketball, Lebron James')
        print('    If the file is under the current directory, you can directly type the file name, e.g., "keywords.txt".')
        print('    If the file is in another directory, please type the full file name, e.g., "C:\\Downloads\\keywords.txt" (for Windows), or "/Users/xy/Downloads/keywords.txt" (for MacOS/Linux).')

        while True:
            file_name = data_directory + input('Type your file name >>> ')
            # The line above is for reading an input file from data directory specified in the beginning of this function.
            if os.path.isfile(file_name):
                break
            else:
                print('"{}" is not a valid file name! Please check if the file exists.\n'.format(file_name))

        # Check the content of keywords file
        key_words = []
        with open(file_name, 'r') as f:
            lines = f.readlines()
            if len(lines) == 0:
                print('\n{} is an empty file!\nTask aborted!'.format(file_name))
                sys.exit(1)

            for line in lines:
                line = line.strip()
                # Detect non-ASCII characters
                for c in line:
                    if ord(c) >= 128:
                        print('\n{} contains non-ASCII characters: "{}" \nPlease remove them and try again'.format(file_name, c))
                        sys.exit(1)
                # Check delimiters
                if line.count(' ') > 1 and ',' not in line:
                    print('\nMore than 1 <space> symbols exist in the key words file, but none comma exists')
                    print('I\'m confused about your keywords. Please separate your key words by commas.')
                    sys.exit(1)

                words = line.split(',')
                for w in words:
                    if len(w.strip()) > 0:
                        key_words.append(w.strip())

        # Check key_words
        if len(key_words) == 0:
            print('\nZero key words are found in {}! Please check your key words file.'.format(file_name))
            sys.exit(1)

    elif m == 'manual':
        print('===========================================================')
        print('Please input your key words (separated by comma), and hit <ENTER> when done.')

        while True:
            line = input('Type the key words >>> ')
            line = line.strip()

            invalid_flag = False
            # Check empty
            if len(line) == 0:
                print('\nYour input is empty! Please try again.')
                invalid_flag = True
            # Detect non-ASCII characters
            for c in line:
                if ord(c) >= 128:
                    print('\nYour input contains non-ASCII characters: "{}"! Please try again.'.format(c))
                    invalid_flag = True
                    break
            # Check delimiters
            if line.count(' ') > 1 and ',' not in line:
                print('\nMore than 1 <space> symbols exist in your input, but none comma exists')
                print('I\'m confused about your keywords. Please try again')
                invalid_flag = True

            if invalid_flag:
                continue
            else:
                break

        # Process input
        key_words = []
        for w in line.split(','):
            if len(w.strip()) > 0:
                key_words.append(w.strip())

    # Print valid key words
    key_words = list(set(key_words))
    print('\n{} unique key words being used: '.format(len(key_words)), key_words)

    # Prompt for number of tweets to be gathered
    print('===========================================================')
    print('How many tweets do you want to gather? \nInput an integer number, or just hit <ENTER> to use the default number 300.')
    num_tweets = 300
    while True:
        s = input('Input an integer >>> ')
        s = s.strip()
        if len(s) == 0:
            break
        elif s.isdigit():
            num = int(s)
            if num > 0:
                num_tweets = num
                break
            else:
                print('\nPlease input a number that is greater than 0.')
        else:
            print('\nPlease input a valid integer number.')

    print('{} tweets to be gathered.'.format(num_tweets))

    # Streaming
    # TODO: remvoe '\t', '\n' and ',' in text field, also remove empty text
    print('===========================================================')
    print('Start gathering tweets ...')

    postfix = current_datetime_str()
    raw_file = 'raw_{}.json'.format(postfix)
    csv_file = 'data_{}.csv'.format(postfix)
    text_file = 'text_{}.csv'.format(postfix)
    
    # The data_directory is the directory in Google Drive, specified in the beginning, that the gathered Tweets will be stored
    raw_path = data_directory + raw_file
    csv_path = data_directory + csv_file
    text_path = data_directory + text_file

    twitter_stream = Stream(auth, MyListener(raw_file=raw_path, csv_file=csv_path, text_file=text_path, max_num=num_tweets))
    twitter_stream.filter(track=key_words)


if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        print('\nTask aborted!')

# !pip install datascience

from datascience import *

"""# Exercise 2 (5 points)
Run the code below to show the tweets file generated.
"""

!ls /content/drive/My\ Drive/DS200Labs/Tweets/

"""# Exercise 3 (10 points)

Find out the name of your tweets file that start with data. Replace XXXXXX in the path assignment below with the rest of the tweets data file. Read the tweets table, and sort it by "text", which is the body of tweets.
"""

path = "/content/drive/My Drive/DS200Labs/Tweets/IRAhandle_tweets_1.csv"
tweets_table = Table.read_table(path)
sorted_tweets = tweets_table.sort("text")
sorted_tweets.show(10)

"""# Counting Words or Hashtags in Tweets

Suppose we are interested in having a high-level view about the frequency that a specific word or a hashtag (e.g., COVID, #Covid or #Covid19) occurs in each tweet. We can do this in a few steps:
- First, convert the string of text (in each tweet) into a list of words using the Python function split.
- Then, count, for each tweet, how many times the word or hashtag you are interested in occurs in the list.  
- Third, add the count for each word or hashtag to obtain a total.

The following Python code demonstrates how split converts a string representation of text into a list of words, which enable further processing of the text.
"""

String = "This is a tweet about tweet, but not a tweet about Covid-19. I don't think it matters, though. #COVID19"
BoW_list = String.split(" ")
print(BoW_list)

BoW_list.count('tweet')

"""# Exercise 4 (5 points)
- (a) Complete the following code so that split uses period "." (not sapce " ") as the delimeter for splitting a given string. 
- (b) Discuss the difference between using period "." versus " " in splitting a string. 
"""

# Exercise 4 (a)
list2 = String.split(".")
print(list2)

"""# Answer to Exercise 4 (b):

The difference between splitting at a "." and a " " is that with a period it splits for sentences and for a space it splits for individual words. 
"""

tweets_BoW = sorted_tweets.apply(lambda x: x.split(' '), "text")

print(tweets_BoW)

TweetsTable_BoW=sorted_tweets.with_column('BoW', tweets_BoW)
TweetsTable_BoW.show(5)

"""# Using .COUNT of List to Compute Word Frequency

We saw the output of applying .split(' ') to a string is a list of words/terms in the string (which we also refer to as "a Bag of Word").  

In the following exercise, we are going to use .count method of a list to count how many times a word occurs in the list. For example, 
"""

String = "This is a tweet about tweet, but not a tweet about Covid-19. #COVID19"
BoW_list = String.split(" ")
print(BoW_list)

# This code returns a number that indicates how many time the list (BoW_list) contains the word "tweet"
BoW_list.count('tweet')

BoW_list.count('#Covid19')

BoW_list.count("#COVID19")

"""# Exercise 5 (10 points)
Select a word or a hashtag you used to sample the tweets, complete the following code for both (a) and (b):
- (a) Determine, for each tweet, the frequency your chosen word (or hashtag) occur in the tweets you gathered using .count method to the "BoW" column of the table TweetsTable_Bow using .COUNT.
- (b) Add the count for each tweet to the table TweetsTable_BoW as a new column.  You can choose the name of the column based on the name of the word or hashtag you used.
 
"""

bible_count = TweetsTable_BoW.apply(lambda x: x.count('Bible'), "BoW")
print(bible_count)

Tweets_Table_BoW_BibCount = TweetsTable_BoW.with_columns("bible_count", bible_count)
Tweets_Table_BoW_BibCount.show(100)